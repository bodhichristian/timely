{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export XGBoost model and artifacts for smart triage UI\n",
        "\n",
        "# 1) Imports and setup\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from model_utils import save_model_artifacts\n",
        "from feature_engineering import TextFeatureExtractor\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "OUTPUT_DIR = 'model_artifacts'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Load processed data and define targets consistent with training\n",
        "\n",
        "df = pd.read_csv('github_issues_processed.csv')\n",
        "\n",
        "cat_targets = [\n",
        "    'is_bug_cat','is_feature_cat','is_doc_cat',\n",
        "    'is_help_cat','is_priority_cat','is_status_cat'\n",
        "]\n",
        "df['category'] = df[cat_targets].idxmax(axis=1)\n",
        "\n",
        "label_targets = [col for col in df.columns if col.startswith('has_')]\n",
        "\n",
        "exclude = cat_targets + label_targets + ['n_labels', 'category']\n",
        "X = df.drop(columns=exclude)\n",
        "y_cat = df['category']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Train/test split (same split strategy)\n",
        "X_train, X_test, y_cat_train, y_cat_test = train_test_split(\n",
        "    X, y_cat, test_size=0.2, random_state=RANDOM_STATE, stratify=y_cat\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) Fit vectorizers/encoders exactly as used downstream\n",
        "# Fit LabelEncoder on training categories (matching training notebook flow)\n",
        "label_encoder = LabelEncoder()\n",
        "y_cat_train_encoded = label_encoder.fit_transform(y_cat_train)\n",
        "y_cat_test_encoded = label_encoder.transform(y_cat_test)\n",
        "\n",
        "# Fit repository encoder from raw data (processed data only has repo_encoded)\n",
        "repo_encoder = LabelEncoder()\n",
        "raw_df = pd.read_csv('github_issues.csv', usecols=['title', 'body', 'repo_name'])\n",
        "repo_series = raw_df['repo_name'].astype(str).fillna('unknown_repo')\n",
        "repo_encoder.fit(repo_series)\n",
        "\n",
        "# Fit TF-IDF on combined text from raw title+body to mirror inference\n",
        "# For export, we only need the fitted vectorizer to match inference; training here uses processed X.\n",
        "tfidf = TfidfVectorizer(max_features=250, stop_words='english', ngram_range=(1,2))\n",
        "combined_text = raw_df[['title', 'body']].fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
        "tfidf.fit(combined_text)\n",
        "\n",
        "# Feature extractor (used only for UI/inference, not training here)\n",
        "feature_extractor = TextFeatureExtractor(tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) Configure XGBoost exactly as training notebook\n",
        "xgb_config = {\n",
        "    'n_estimators': 200,\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 5,\n",
        "    'min_child_weight': 2,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'multi:softprob'\n",
        "}\n",
        "\n",
        "# Set num_class from training labels\n",
        "xgb_config['num_class'] = len(np.unique(y_cat_train_encoded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost with SMOTE — quick eval on holdout\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     is_bug_cat       0.96      0.99      0.97      2961\n",
            "     is_doc_cat       0.52      0.35      0.42        79\n",
            " is_feature_cat       0.64      0.35      0.45       119\n",
            "    is_help_cat       0.00      0.00      0.00         3\n",
            "is_priority_cat       0.00      0.00      0.00         1\n",
            "  is_status_cat       0.90      1.00      0.95        28\n",
            "\n",
            "       accuracy                           0.94      3191\n",
            "      macro avg       0.50      0.45      0.47      3191\n",
            "   weighted avg       0.93      0.94      0.94      3191\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 6) Train XGBoost with SMOTE on the processed feature matrix (as in training)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "xgb_pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=RANDOM_STATE, k_neighbors=2)),\n",
        "    ('xgb', xgb.XGBClassifier(**xgb_config))\n",
        "])\n",
        "\n",
        "xgb_pipeline.fit(X_train, y_cat_train_encoded)\n",
        "\n",
        "y_pred_encoded = xgb_pipeline.predict(X_test)\n",
        "y_proba = xgb_pipeline.predict_proba(X_test)\n",
        "\n",
        "# For sanity: decode for a quick classification report\n",
        "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "print(\"XGBoost with SMOTE — quick eval on holdout\")\n",
        "print(classification_report(y_cat_test, y_pred, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifacts to: model_artifacts\n"
          ]
        }
      ],
      "source": [
        "# 7) Persist model and artifacts for UI inference\n",
        "# We save the trained pipeline's XGB classifier, the TF-IDF vectorizer, the label encoder, and the repo encoder.\n",
        "\n",
        "# Extract the trained XGB model from pipeline for saving\n",
        "trained_model = xgb_pipeline.named_steps['xgb']\n",
        "\n",
        "save_model_artifacts(\n",
        "    model=trained_model,\n",
        "    tfidf_vectorizer=tfidf,\n",
        "    label_encoder=label_encoder,\n",
        "    repo_encoder=repo_encoder,\n",
        "    output_dir=OUTPUT_DIR\n",
        ")\n",
        "\n",
        "print(f\"Saved artifacts to: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8) Reload modules to pick up updated feature schema\n",
        "import importlib, feature_engineering, smart_triage\n",
        "importlib.reload(feature_engineering)\n",
        "importlib.reload(smart_triage)\n",
        "from smart_triage import SmartIssueTriage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model features (count): 659\n",
            "Input features (count): 659\n",
            "First 10 input cols: ['created_hour', 'created_day_of_week', 'created_month', 'n_days_to_resolution', 'title_length', 'body_length', 'title_word_count', 'body_word_count', 'code_block_count', 'url_count']\n",
            "{\n",
            "  \"primary_category\": {\n",
            "    \"category\": \"is_bug_cat\",\n",
            "    \"confidence\": 0.9812637567520142,\n",
            "    \"action_needed\": true\n",
            "  },\n",
            "  \"secondary_suggestions\": [],\n",
            "  \"triage_recommendations\": [\n",
            "    {\n",
            "      \"type\": \"high_confidence_bug\",\n",
            "      \"message\": \"High confidence bug report - Immediate review recommended\",\n",
            "      \"priority\": \"high\"\n",
            "    }\n",
            "  ],\n",
            "  \"repo_context\": {\n",
            "    \"repository\": \"2dust/v2rayN\",\n",
            "    \"typical_response_time\": \"2-3 days\",\n",
            "    \"similar_issues_count\": 5\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 9) Quick verification snippet for UI-like prediction with reloaded modules\n",
        "triage = SmartIssueTriage(model_dir=OUTPUT_DIR)\n",
        "\n",
        "sample_title = \"Error in login flow: users cannot reset password\"\n",
        "sample_body = \"Users report password reset links error out with 500. Happens since v2.3.\"\n",
        "sample_repo = repo_encoder.classes_[0]\n",
        "\n",
        "features = triage.feature_extractor.extract_all_features(\n",
        "    text=f\"{sample_title}\\n{sample_body}\",\n",
        "    repo=sample_repo,\n",
        "    repo_encoder=repo_encoder\n",
        ")\n",
        "\n",
        "# Debug: print feature names vs model booster names if mismatch persists\n",
        "model_feature_names = triage.model.get_booster().feature_names\n",
        "first_10 = features.columns.tolist()[:10]\n",
        "print(\"Model features (count):\", len(model_feature_names))\n",
        "print(\"Input features (count):\", features.shape[1])\n",
        "print(\"First 10 input cols:\", first_10)\n",
        "\n",
        "result = triage.predict(\n",
        "    title=sample_title,\n",
        "    body=sample_body,\n",
        "    repo=sample_repo,\n",
        "    threshold=0.35\n",
        ")\n",
        "\n",
        "print(json.dumps(result, indent=2)[:2000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"primary_category\": {\n",
            "    \"category\": \"is_bug_cat\",\n",
            "    \"confidence\": 0.9812637567520142,\n",
            "    \"action_needed\": true\n",
            "  },\n",
            "  \"secondary_suggestions\": [],\n",
            "  \"triage_recommendations\": [\n",
            "    {\n",
            "      \"type\": \"high_confidence_bug\",\n",
            "      \"message\": \"High confidence bug report - Immediate review recommended\",\n",
            "      \"priority\": \"high\"\n",
            "    }\n",
            "  ],\n",
            "  \"repo_context\": {\n",
            "    \"repository\": \"2dust/v2rayN\",\n",
            "    \"typical_response_time\": \"2-3 days\",\n",
            "    \"similar_issues_count\": 5\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 8) Quick verification snippet for UI-like prediction\n",
        "from smart_triage import SmartIssueTriage\n",
        "\n",
        "triage = SmartIssueTriage(model_dir=OUTPUT_DIR)\n",
        "\n",
        "sample_title = \"Error in login flow: users cannot reset password\"\n",
        "sample_body = \"Users report password reset links error out with 500. Happens since v2.3.\"\n",
        "# pick a repo from the fitted encoder classes for a valid mapping\n",
        "sample_repo = repo_encoder.classes_[0]\n",
        "\n",
        "result = triage.predict(\n",
        "    title=sample_title,\n",
        "    body=sample_body,\n",
        "    repo=sample_repo,\n",
        "    threshold=0.35\n",
        ")\n",
        "\n",
        "print(json.dumps(result, indent=2)[:2000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
